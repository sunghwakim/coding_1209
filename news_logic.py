import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
from datetime import datetime
import streamlit as st
import urllib.parse
import random

def fetch_rss_feeds(feeds_list):
    """RSS í”¼ë“œ ìˆ˜ì§‘ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    articles = []
    if not feeds_list: return articles
    
    for feed in feeds_list:
        try:
            feed_url = feed.get('url', '')
            if not feed_url: continue
            parsed = feedparser.parse(feed_url)
            source_name = feed.get('name', 'Unknown Source')
            
            if not parsed.entries: continue
            for entry in parsed.entries[:5]:
                if not hasattr(entry, 'title') or not entry.title: continue
                title = entry.title
                link = entry.get('link', '')
                published = entry.get('published', str(datetime.now()))
                summary_raw = entry.get('summary', entry.get('description', ''))
                try: summary_clean = BeautifulSoup(summary_raw, "html.parser").get_text()[:300]
                except: summary_clean = summary_raw[:300] if summary_raw else ""
                articles.append({"source": source_name, "title": title, "link": link, "summary": summary_clean, "published": published})
        except: continue
    return articles

def generate_infographic(prompt):
    """
    âœ¨ ê³ í™”ì§ˆ(Flux) ì¸í¬ê·¸ë˜í”½ ìƒì„± í•¨ìˆ˜
    URL ì„¤ì • ì—†ì´ë„, ìµœì‹  AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 4Kê¸‰ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # 1. í”„ë¡¬í”„íŠ¸ ê°•í™”: 'ì¸í¬ê·¸ë˜í”½', 'ê³ í™”ì§ˆ', '4K' ê°™ì€ ë‹¨ì–´ë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€
        enhanced_prompt = f"infographic, data visualization, flat design, high quality, 4k, detailed, professional, {prompt}"
        
        # 2. ì¸í„°ë„· ì£¼ì†Œìš©ìœ¼ë¡œ ë³€í™˜
        encoded_prompt = urllib.parse.quote(enhanced_prompt)
        
        # 3. ë§¤ë²ˆ ë‹¤ë¥¸ ê·¸ë¦¼ì´ ë‚˜ì˜¤ë„ë¡ ëœë¤ ë²ˆí˜¸ ìƒì„±
        seed = random.randint(1, 99999)
        
        # 4. ê³ í™”ì§ˆ ëª¨ë¸(Flux) í˜¸ì¶œ URL ìƒì„±
        # (ì´ ì£¼ì†ŒëŠ” í‚¤ ì—†ì´ë„ ê³ í™”ì§ˆì„ ë½‘ì•„ì£¼ëŠ” ë§ˆë²•ì˜ ì£¼ì†Œì…ë‹ˆë‹¤)
        image_url = f"https://pollinations.ai/p/{encoded_prompt}?width=1024&height=600&seed={seed}&model=flux"
        
        return image_url

    except Exception as e:
        # ì‹¤íŒ¨ ì‹œì—ë§Œ ì €í™”ì§ˆ(picsum) ì‚¬ìš©
        return "https://picsum.photos/800/400"

def analyze_news_with_gemini(articles):
    """ë‚˜ë…¸ë°”ë‚˜ë‚˜ í‚¤(Gemini)ë¡œ ë¶„ì„ + ê³ í™”ì§ˆ ê·¸ë¦¼"""
    if not articles: return None, None

    # 1. API í‚¤ ì—°ê²° (ì‚¬ìš©ìë‹˜ì´ ì£¼ì‹  í‚¤ ì‚¬ìš©)
    try:
        api_key = st.secrets["GOOGLE_API_KEY"] 
        genai.configure(api_key=api_key)
    except Exception as e:
        return f"âŒ API í‚¤ ì„¤ì • ì˜¤ë¥˜: secrets.tomlì— GOOGLE_API_KEYê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", None

    # 2. ëª¨ë¸ ì„¤ì • (ì‚¬ìš©ì í‚¤ì— ë§ëŠ” ëª¨ë¸ ìë™ íƒìƒ‰)
    candidate_models = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']

    news_text = ""
    for idx, art in enumerate(articles):
        news_text += f"{idx+1}. [{art.get('source')}] {art.get('title')}\n"

    # 3. AIì—ê²Œ ë‚´ë¦¬ëŠ” ì§€ë ¹ (í”„ë¡¬í”„íŠ¸)
    prompt = f"""
    ë„ˆëŠ” IT ì „ë¬¸ ë‰´ìŠ¤ ì•µì»¤ì•¼.
    1. **ë‰´ìŠ¤ ë¸Œë¦¬í•‘**: 'ğŸ“¢ ì˜¤ëŠ˜ì˜ í•µì‹¬ íë¦„' (3ì¤„ ìš”ì•½) ë° ë‰´ìŠ¤ ì •ë¦¬ (ë§ˆí¬ë‹¤ìš´)
    2. **ê·¸ë¦¼ ìš”ì²­**: ì´ ë‰´ìŠ¤ ë‚´ìš©ì„ í•œ ì¥ì˜ ì¸í¬ê·¸ë˜í”½ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” **ì˜ì–´ ë¬˜ì‚¬(English Prompt)** í•œ ì¤„.
       (ì˜ˆ: futuristic network map with glowing blue nodes, cyber security shield, 3d render, white background)

    **ë°˜í™˜ í˜•ì‹ (ì´ëŒ€ë¡œë§Œ ëŒ€ë‹µí•´):**
    (ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ë‚´ìš©)
    ---êµ¬ë¶„ì„ ---
    (ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸)

    [ë‰´ìŠ¤ ëª©ë¡]
    {news_text}
    """

    # 4. ë¶„ì„ ì‹¤í–‰
    last_error = ""
    for model_name in candidate_models:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            full_text = response.text
            
            parts = full_text.split('---êµ¬ë¶„ì„ ---')
            briefing_text = parts[0].strip()
            image_url = None
            
            if len(parts) > 1:
                image_prompt = parts[1].strip()
                # âœ¨ ê³ í™”ì§ˆ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
                image_url = generate_infographic(image_prompt)
            
            return briefing_text, image_url
            
        except Exception as e:
            last_error = str(e)
            continue

    return f"âŒ ë¶„ì„ ì‹¤íŒ¨: {last_error}", None